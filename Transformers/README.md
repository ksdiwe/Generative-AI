
## Transformers

Transformers are a game-changer in how we handle language processing in AI. 

Here are a few topics I've explored:
1. Self-Attention Mechanism:
2. Scaled Dot Product Attention:
3. Transformer Architecture:
4. Encoder-Decoder Stack
5. Attention in Detail
6. Positional Encoding Matrix
